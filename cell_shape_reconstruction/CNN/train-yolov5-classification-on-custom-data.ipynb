{"cells":[{"cell_type":"markdown","metadata":{"id":"5GYQX3of4QiW"},"source":["# YOLOv5 Classification Tutorial\n","\n","YOLOv5 supports classification tasks too. This is the official YOLOv5 classification notebook tutorial. YOLOv5 is maintained by [Ultralytics](https://github.com/ultralytics/yolov5).\n","\n","This notebook covers:\n","\n","*   Inference with out-of-the-box YOLOv5 classification on ImageNet\n","*  [Training YOLOv5 classification](https://blog.roboflow.com//train-YOLOv5-classification-custom-data) on custom data\n","\n","*Looking for custom data? Explore over 66M community datasets on [Roboflow Universe](https://universe.roboflow.com).*\n","\n","This notebook was created with Google Colab. [Click here](https://colab.research.google.com/drive/1FiSNz9f_nT8aFtDEU3iDAQKlPT8SCVni?usp=sharing) to run it."]},{"cell_type":"markdown","metadata":{"id":"-PJ8vlYXbWtN"},"source":["# Setup\n","\n","Pull in respective libraries to prepare the notebook environment."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23321,"status":"ok","timestamp":1718954166328,"user":{"displayName":"Ãlvaro","userId":"09855394299918397443"},"user_tz":-120},"id":"INqNYyE9lIDD","outputId":"4b8d58cf-1148-41a4-e0a5-9eff3f61a5ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: no se puede crear el directorio Â«/home/araya/CSIC_IARB/CSIC_IARBÂ»: El archivo ya existe\n","/home/araya/CSIC_IARB/CSIC_IARB\n","/home/araya/CSIC_IARB/CSIC_IARB\n"]}],"source":["\n","import os\n","HOME = os.getcwd()\n","!mkdir {HOME}\n","print(HOME)\n","%cd {HOME}"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9431,"status":"ok","timestamp":1718886337321,"user":{"displayName":"Ãlvaro","userId":"09855394299918397443"},"user_tz":-120},"id":"pIM7fOwm8A7l","outputId":"178b91a6-d95a-4a2e-acce-bc86bc5ec2c6"},"outputs":[{"name":"stderr","output_type":"stream","text":["YOLOv5 ðŸš€ v7.0-330-gb20fa802 Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (Quadro GV100, 32492MiB)\n"]},{"name":"stdout","output_type":"stream","text":["Setup complete âœ… (20 CPUs, 62.5 GB RAM, 870.1/937.3 GB disk)\n"]}],"source":["\n","!ls\n","!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt  # install\n","\n","import torch\n","import utils\n","display = utils.notebook_init()  # checks"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1718955361743,"user":{"displayName":"Ãlvaro","userId":"09855394299918397443"},"user_tz":-120},"id":"6IIgJbP7G6Th","outputId":"2e1b82ae-a0c2-41da-d07e-034eccfd5947"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/araya/new_batch\n"]}],"source":["# Ensure we're in the right directory to download our custom dataset\n","import os\n","os.makedirs(\"../new_batch/\", exist_ok=True)\n","%cd ../new_batch/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33342,"status":"ok","timestamp":1718955005728,"user":{"displayName":"Ãlvaro","userId":"09855394299918397443"},"user_tz":-120},"id":"He6JwHIlG-W_","outputId":"2520815a-6e98-40a5-9208-8bb40e2da9f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: roboflow in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (1.1.33)\n","Requirement already satisfied: certifi in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (2024.6.2)\n","Requirement already satisfied: chardet==4.0.0 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: idna==3.7 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (3.7)\n","Requirement already satisfied: cycler in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (1.4.4)\n","Requirement already satisfied: matplotlib in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (3.4.3)\n","Requirement already satisfied: numpy>=1.18.5 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (1.24.4)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (4.10.0.84)\n","Requirement already satisfied: Pillow>=7.1.2 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (10.3.0)\n","Requirement already satisfied: python-dateutil in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (2.9.0)\n","Requirement already satisfied: python-dotenv in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (1.0.1)\n","Requirement already satisfied: requests in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (2.32.3)\n","Requirement already satisfied: six in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (2.2.2)\n","Requirement already satisfied: tqdm>=4.41.0 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (4.66.4)\n","Requirement already satisfied: PyYAML>=5.3.1 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (6.0)\n","Requirement already satisfied: requests-toolbelt in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: python-magic in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from roboflow) (0.4.27)\n","Requirement already satisfied: pyparsing>=2.2.1 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from matplotlib->roboflow) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/araya/.conda/envs/ultralytics-env/lib/python3.8/site-packages (from requests->roboflow) (3.3.2)\n","Note: you may need to restart the kernel to use updated packages.\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in class-yeast-6 to folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8005/8005 [00:01<00:00, 6734.56it/s] "]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to class-yeast-6 in folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3625/3625 [00:00<00:00, 15523.28it/s]\n"]}],"source":["# REPLACE the below with your exported code snippet from above\n","%pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"fekKRSnXXfEB49ck6xjp\")\n","project = rf.workspace(\"raspberry-nv8s6\").project(\"class-yeast\")\n","version = project.version(6)\n","dataset = version.download(\"folder\")\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":250,"status":"ok","timestamp":1718955084151,"user":{"displayName":"Ãlvaro","userId":"09855394299918397443"},"user_tz":-120},"id":"wLQbThFICpn4"},"outputs":[],"source":["#Save the dataset name to the environment so we can use it in a system call later\n","dataset_name = dataset.location.split(os.sep)[-1]\n","os.environ[\"DATASET_NAME\"] = dataset_name"]},{"cell_type":"markdown","metadata":{"id":"-5z7Yv42FGrK"},"source":["### Train On Custom Data ðŸŽ‰\n","Here, we use the DATASET_NAME environment variable to pass our dataset to the `--data` parameter.\n","\n","Note: we're training for 100 epochs here. We're also starting training from the pretrained weights. Larger datasets will likely benefit from longer training."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"MXWTTN2BEaqe"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/araya/CSIC_IARB\n","\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, data=/home/araya/CSIC_IARB/CSIC_IARB/new_batch/class-yeast-6, epochs=100, batch_size=64, imgsz=128, nosave=False, cache=None, device=, workers=8, project=CSIC_IARB/new_batch/yolov5/runs/train-cls, name=exp, exist_ok=False, pretrained=yolov5s-cls.pt, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v7.0-331-gab364c98 Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (Quadro GV100, 32492MiB)\n","\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir CSIC_IARB/new_batch/yolov5/runs/train-cls', view at http://localhost:6006/\n","\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, size=(128, 128), scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0.0, 0.0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, normalization='standard'), ToTensorV2(p=1.0, transpose_mask=False)\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-cls.pt to yolov5s-cls.pt...\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.5M/10.5M [00:00<00:00, 16.4MB/s]\n","\n","Model summary: 149 layers, 4176323 parameters, 4176323 gradients, 10.5 GFLOPs\n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 32 weight(decay=0.0), 33 weight(decay=5e-05), 33 bias\n","Image sizes 128 train, 128 test\n","Using 8 dataloader workers\n","Logging results to \u001b[1mCSIC_IARB/new_batch/yolov5/runs/train-cls/exp11\u001b[0m\n","Starting yolov5s-cls.pt training on /home/araya/CSIC_IARB/CSIC_IARB/new_batch/class-yeast-6 dataset with 3 classes for 100 epochs...\n","\n","     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n","     1/100    0.883G        1.02        1.02       0.438           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     2/100    0.883G       0.932        1.03        0.44           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     3/100    0.883G       0.872        0.82       0.648           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     4/100    0.883G       0.838       0.927       0.562           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     5/100    0.883G        0.84        1.36       0.497           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     6/100    0.883G       0.822       0.813       0.622           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     7/100    0.883G        0.81       0.672       0.801           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     8/100    0.883G       0.777       0.588       0.815           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","     9/100    0.883G       0.776        0.68       0.793           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    10/100    0.883G       0.765       0.577       0.889           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    11/100    0.883G       0.747       0.611       0.849           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    12/100    0.883G       0.724       0.741       0.747           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    13/100    0.883G       0.729       0.573       0.861           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    14/100    0.883G       0.723       0.566        0.83           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    15/100    0.883G       0.722       0.609       0.824           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    16/100    0.883G       0.717       0.874       0.665           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    17/100    0.883G       0.705       0.584       0.844           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    18/100    0.883G       0.695        0.76        0.71           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    19/100    0.883G       0.696       0.531       0.878           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    20/100    0.883G       0.677        0.56       0.869           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    21/100    0.883G       0.683        0.49       0.895           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    22/100    0.883G       0.663       0.457       0.912           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    23/100    0.883G        0.68       0.508       0.901           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    24/100    0.883G       0.673       0.443       0.926           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    25/100    0.883G       0.672       0.508       0.909           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    26/100    0.883G       0.666       0.464       0.906           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    27/100    0.883G       0.662       0.631       0.844           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    28/100    0.883G       0.658       0.464       0.915           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    29/100    0.883G       0.645       0.535       0.884           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    30/100    0.883G       0.646       0.565       0.875           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    31/100    0.883G       0.664       0.529       0.889           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    32/100    0.883G        0.63       0.478       0.906           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    33/100    0.883G       0.648       0.445       0.918           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    34/100    0.883G       0.648       0.457       0.923           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    35/100    0.883G       0.641       0.464       0.918           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    36/100    0.883G       0.626       0.475       0.918           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    37/100    0.883G       0.638       0.467       0.915           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    38/100    0.883G       0.618        0.45       0.938           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    39/100    0.883G       0.632       0.441        0.92           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    40/100    0.883G       0.612       0.507       0.912           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    41/100    0.883G       0.627       0.429       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    42/100    0.883G       0.644       0.453       0.912           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    43/100    0.883G       0.623        0.44        0.94           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    44/100    0.883G       0.606       0.486       0.912           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    45/100    0.883G       0.614        0.43        0.92           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    46/100    0.883G       0.625       0.414        0.94           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    47/100    0.883G        0.61       0.475       0.901           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    48/100    0.883G       0.617       0.424       0.952           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    49/100    0.883G       0.594       0.418       0.946           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    50/100    0.883G       0.602        0.44       0.929           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    51/100    0.883G       0.594        0.42       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    52/100    0.883G       0.598       0.418       0.929           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    53/100    0.883G       0.599         0.4       0.943           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    54/100    0.883G       0.604       0.437        0.92           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    55/100    0.883G       0.612       0.409        0.94           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    56/100    0.883G       0.594       0.448       0.923           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    57/100    0.883G       0.594       0.421       0.932           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    58/100    0.883G       0.604       0.411       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    59/100    0.883G       0.594       0.416       0.943           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    60/100    0.883G       0.602       0.421       0.929           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    61/100    0.883G       0.592       0.451       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    62/100    0.883G       0.594       0.417       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    63/100    0.883G       0.593       0.424       0.926           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    64/100    0.883G       0.578        0.39       0.955           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    65/100    0.883G       0.562       0.392       0.949           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    66/100    0.883G       0.586       0.398       0.952           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    67/100    0.883G       0.567       0.405       0.957           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    68/100    0.883G       0.575       0.403       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    69/100    0.883G        0.58       0.391        0.94           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    70/100    0.883G       0.571       0.392       0.949           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    71/100    0.883G       0.571       0.425       0.932           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    72/100    0.883G       0.571       0.411       0.935           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    73/100    0.883G       0.568       0.393       0.955           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    74/100    0.883G       0.567       0.407       0.938           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    75/100    0.883G        0.56       0.393       0.955           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    76/100    0.883G       0.557       0.386       0.957           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    77/100    0.883G       0.561       0.394       0.943           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    78/100    0.883G       0.572       0.395       0.957           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    79/100    0.883G       0.549       0.412       0.938           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    80/100    0.883G       0.571       0.388       0.957           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    81/100    0.883G        0.57       0.392       0.957           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    82/100    0.883G       0.549       0.379       0.955           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    83/100    0.883G       0.554       0.386       0.952           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    84/100    0.883G        0.55       0.382       0.969           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    85/100    0.883G        0.55       0.377       0.963           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    86/100    0.883G        0.55       0.375       0.966           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    87/100    0.883G       0.542       0.377       0.972           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    88/100    0.883G       0.531       0.378       0.969           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    89/100    0.883G       0.535        0.38       0.966           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    90/100    0.883G       0.549       0.375       0.957           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    91/100    0.883G       0.548       0.373       0.974           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    92/100    0.883G       0.542       0.372       0.972           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    93/100    0.883G       0.524       0.364       0.972           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    94/100    0.883G       0.539       0.368       0.969           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    95/100    0.883G       0.535       0.368       0.969           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    96/100    0.883G       0.521       0.372       0.969           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    97/100    0.883G       0.538       0.382        0.96           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    98/100    0.883G        0.53       0.374       0.966           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","    99/100    0.883G       0.521       0.374       0.963           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","   100/100    0.883G       0.528        0.37       0.966           1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n","\n","Training complete (0.056 hours)\n","Results saved to \u001b[1mCSIC_IARB/new_batch/yolov5/runs/train-cls/exp11\u001b[0m\n","Predict:         python classify/predict.py --weights CSIC_IARB/new_batch/yolov5/runs/train-cls/exp11/weights/best.pt --source im.jpg\n","Validate:        python classify/val.py --weights CSIC_IARB/new_batch/yolov5/runs/train-cls/exp11/weights/best.pt --data /home/araya/CSIC_IARB/CSIC_IARB/new_batch/class-yeast-6\n","Export:          python export.py --weights CSIC_IARB/new_batch/yolov5/runs/train-cls/exp11/weights/best.pt --include onnx\n","PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'CSIC_IARB/new_batch/yolov5/runs/train-cls/exp11/weights/best.pt')\n","Visualize:       https://netron.app\n","\n"]}],"source":["%cd /home/araya/CSIC_IARB\n","#!git clone https://github.com/ultralytics/yolov5\n","#%pip install albumentations\n","!python CSIC_IARB/new_batch/yolov5/classify/train.py --model yolov5s-cls.pt --data /home/araya/CSIC_IARB/CSIC_IARB/new_batch/class-yeast-6 --epochs 100 --img 128 --pretrained yolov5s-cls.pt"]},{"cell_type":"markdown","metadata":{"id":"HHUFGeLbGd98"},"source":["### Validate Your Custom Model\n","\n","Repeat step 2 from above to test and validate your custom model."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"DIV7ydyKGZFL"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/araya/CSIC_IARB\n","\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/home/araya/CSIC_IARB/CSIC_IARB/new_batch/class-yeast-6, weights=['CSIC_IARB/new_batch/yolov5/runs/train-cls/exp11/weights/best.pt'], batch_size=128, imgsz=224, device=, workers=8, verbose=True, project=CSIC_IARB/new_batch/yolov5/runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 ðŸš€ v7.0-331-gab364c98 Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (Quadro GV100, 32492MiB)\n","\n","Fusing layers... \n","Model summary: 117 layers, 4170531 parameters, 0 gradients, 10.4 GFLOPs\n","testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n","                   Class      Images    top1_acc    top5_acc\n","                     all         352       0.955           1\n","                       0         154       0.987           1\n","                       1         156       0.923           1\n","                       2          42       0.952           1\n","Speed: 0.1ms pre-process, 1.8ms inference, 0.1ms post-process per image at shape (1, 3, 224, 224)\n","Results saved to \u001b[1mCSIC_IARB/new_batch/yolov5/runs/val-cls/exp3\u001b[0m\n"]}],"source":["%cd /home/araya/CSIC_IARB\n","!python CSIC_IARB/new_batch/yolov5/classify/val.py --weights CSIC_IARB/new_batch/yolov5/runs/train-cls/exp11/weights/best.pt --data /home/araya/CSIC_IARB/CSIC_IARB/new_batch/class-yeast-6"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"uH5tJNpEsi6g"},"source":["### Infer With Your Custom Model"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"81lK1hU_sk54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Inferring on an example of the class '2'\n","\u001b[34m\u001b[1mclassify/predict: \u001b[0mweights=['runs/train-cls/exp10/weights/best.pt'], source=/home/araya/CSIC_IARB/CSIC_IARB/datasets/class-yeast-5/test/2/croppedImage_288_1_png.rf.ff9f9d351a71b3c372431b793e45892f.jpg, data=data/coco128.yaml, imgsz=[224, 224], device=, view_img=False, save_txt=False, nosave=False, augment=False, visualize=False, update=False, project=runs/predict-cls, name=exp, exist_ok=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 ðŸš€ v7.0-326-gec331cbd Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (Quadro GV100, 32492MiB)\n","\n","Fusing layers... \n","Model summary: 117 layers, 4170531 parameters, 0 gradients, 10.4 GFLOPs\n","image 1/1 /home/araya/CSIC_IARB/CSIC_IARB/datasets/class-yeast-5/test/2/croppedImage_288_1_png.rf.ff9f9d351a71b3c372431b793e45892f.jpg: 224x224 2 0.61, 1 0.25, 0 0.15, 3.2ms\n","Speed: 0.2ms pre-process, 3.2ms inference, 13.4ms NMS per image at shape (1, 3, 224, 224)\n","Results saved to \u001b[1mruns/predict-cls/exp2\u001b[0m\n"]}],"source":["#Get the path of an image from the test or validation set\n","if os.path.exists(os.path.join(dataset.location, \"test\")):\n","  split_path = os.path.join(dataset.location, \"test\")\n","else:\n","  os.path.join(dataset.location, \"valid\")\n","example_class = os.listdir(split_path)[0]\n","example_image_name = os.listdir(os.path.join(split_path, example_class))[0]\n","example_image_path = os.path.join(split_path, example_class, example_image_name)\n","os.environ[\"TEST_IMAGE_PATH\"] = example_image_path\n","\n","print(f\"Inferring on an example of the class '{example_class}'\")\n","\n","#Infer\n","!python classify/predict.py --weights runs/train-cls/exp10/weights/best.pt --source $TEST_IMAGE_PATH"]},{"cell_type":"markdown","metadata":{"id":"DdGuG-1kNjWT"},"source":["We can see the inference results show ~3ms inference and the respective classes predicted probabilities."]},{"cell_type":"markdown","metadata":{"id":"I38IM6NXKNN9"},"source":["## (OPTIONAL) Improve Our Model with Active Learning\n","\n","Now that we've trained our model once, we will want to continue to improve its performance. Improvement is largely dependent on improving our dataset.\n","\n","We can programmatically upload example failure images back to our custom dataset based on conditions (like seeing an underrpresented class or a low confidence score) using the same `pip` package."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"HycgSEnYKo0J"},"outputs":[],"source":["# # Upload example image\n","image_path = example_image_path\n","project.upload(image_path)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"VwXDoz_vLK3V"},"outputs":[{"ename":"IndentationError","evalue":"expected an indented block (1363339861.py, line 4)","output_type":"error","traceback":["\u001b[0;36m  Input \u001b[0;32mIn [27]\u001b[0;36m\u001b[0m\n\u001b[0;31m    if pred[\"score\"] < min_conf:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}],"source":["# # Example upload code\n","min_conf = float(\"inf\")\n","for pred in results:\n","if pred[\"score\"] < min_conf:\n","    min_conf = pred[\"score\"]\n","if min_conf < 0.4:\n","    project.upload(image_path)"]},{"cell_type":"markdown","metadata":{"id":"aYlfaHDusN-j"},"source":["# (BONUS) YOLOv5 classify/predict.py Accepts Several Input Methods\n","- Webcam: `python classify/predict.py --weights yolov5s-cls.pt --source 0`\n","- Image `python classify/predict.py --weights yolov5s-cls.pt --source img.jpg`\n","- Video: `python classify/predict.py --weights yolov5s-cls.pt --source vid.mp4`\n","- Directory: `python classify/predict.py --weights yolov5s-cls.pt --source path/`\n","- Glob: `python classify/predict.py --weights yolov5s-cls.pt --source 'path/*.jpg'`\n","- YouTube: `python classify/predict.py --weights yolov5s-cls.pt --source 'https://youtu.be/Zgi9g1ksQHc'`\n","- RTSP, RTMP, HTTP stream: `python classify/predict.py --weights yolov5s-cls.pt --source 'rtsp://example.com/media.mp4'`"]},{"cell_type":"markdown","metadata":{"id":"iKSP-SNTvcLJ"},"source":["###Directory Example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwSoHcHcvjeD"},"outputs":[],"source":["#Directory infer\n","os.environ[\"TEST_CLASS_PATH\"] = test_class_path = os.path.join(*os.environ[\"TEST_IMAGE_PATH\"].split(os.sep)[:-1])\n","print(f\"Infering on all images from the directory {os.environ['TEST_CLASS_PATH']}\")\n","!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source /$TEST_CLASS_PATH/"]},{"cell_type":"markdown","metadata":{"id":"kCCao9t8se8i"},"source":["###YouTube Example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heebjpJBsakV"},"outputs":[],"source":["#YouTube infer\n","!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source 'https://www.youtube.com/watch?v=7AlYA4ItA74'"]},{"cell_type":"markdown","metadata":{"id":"06O7jpy7W01Z"},"source":["# Export to matlab format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzkJGN9UW4Y4"},"outputs":[],"source":["import torch\n","from yolov5 import YOLOv5\n","\n","# Load YOLOv5 model\n","model = YOLOv5('yolov5s', pretrained=True)\n","\n","# Save the model\n","model.to_onnx('best_model.onnx', opset_version=12)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","provenance":[{"file_id":"https://github.com/roboflow-ai/notebooks/blob/main/notebooks/train-yolov5-classification-on-custom-data.ipynb","timestamp":1718881473703}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
